<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Weijun Wang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Weijun Wang</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="services.html">Services</a></div>
<div class="menu-item"><a href="bio.html">Biography</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="papers.html">Publications</a></div>
<div class="menu-item"><a href="Research.html">Fundings</a></div>
<div class="menu-item"><a href="students.html">Students</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Weijun Wang (王蔚峻)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="img/wwj.jpg" alt="alt text" width="WIDTHpx" height="200px" />&nbsp;</td>
<td align="left"><p>Postdoctoral Fellow <br />
<a href="https://air.tsinghua.edu.cn/index.htm">Institute for AI Industry Research</a> <br />
<a href="https://www.tsinghua.edu.cn/en/index.htm">Tsinghua University</a><br />
Beijing, China <br />
Email: wangweijun AT mail DOT tsinghua DOT edu DOT cn<br /></p>
<p>Find me at  <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=ApKD824AAAAJ"><img src="img/googlescholar.png" alt="linkedin" height="32px" style="vertical-align:middle" /></a>
<a href="https://github.com/WeijunAlexWang"><img src="img/github.png" alt="github" height="32px" style="vertical-align:middle" /></a>
</p>
<!-- Left photo was taken in the tomb of Pharaohs Ramesses II at the Valley of the Kings near Luxor, Egypt. Definitely worth visiting! -->
<!--The left photo was taken close to Taksim Square in Istanbul. -->
<br /></p>
</td>
</tr></table>
<!-- <p style="color:rgb(116, 52, 133)">Our team is recruiting <a href="https://air.tsinghua.edu.cn/info/1030/1564.htm">research interns</a>. Please feel free to contact us if you are interested. </p> -->
<h2>Research Interests</h2>
<p><b>My current research interest is building systems to boost large models serving, and empowering traditional systems with large models.</b></p>
<h2>Current Projects</h2>
<ul>
  <li>
    <b><p>Machine Learning for System</p></b>
    <ul>
      <!-- <li><p>Multi-Modal Video Analytics System. </p> </li> -->
      <li><p>LMM-powered Vision Applications: <a href="https://arxiv.org/pdf/2411.00915">VaLoRA [EuroSys]</a></p></li>
    </ul>
  </li>  
  <li>
    <b><p>System for Machine Learning</p></b>
    <ul>
      <li><p>System-optimized Video Analytics: <a href="https://arxiv.org/pdf/2407.16990">RegenHance [NSDI]</a>, <a href="https://www.researchgate.net/publication/379527692_Accelerated_Neural_Enhancement_for_Video_Analytics_With_Video_Quality_Adaptation#fullTextFileContent">AccDecoder [TON]</a>, <a href="http://arxiv.org/abs/2312.15740">BiSwift [INFOCOM]</a></p></li>
      <li><p>Resource-constraint LLM Serving System: <a href="https://arxiv.org/pdf/2308.15030v4">SwapMoE [ACL]</a>, <a href="https://arxiv.org/pdf/2405.17741">LoRA-Switch [arXiv]</a></p></li>
    </ul>
  </li>
</ul>
<h2>Recent Publications (<a href="papers.html">full list</a>)</h2>
<ul>
<li><p>&ldquo;<a href="https://arxiv.org/pdf/2411.00915">Empower Vision Applications with LoRA LMM</a>&rdquo;, EuroSys 2025.</p></li>  
<li><p>&ldquo;<a href=" https://arxiv.org/pdf/2407.16990">Region-based Content Enhancement for Efficient Video Analytics at the Edge</a>&rdquo;, NSDI 2025.</p></li>
<li><p>&ldquo;<a href="https://arxiv.org/pdf/2308.15030v4">SwapMoE: Serving Off-the-shelf MoE-based Large Language Models with Tunable Memory Budget</a>&rdquo;, ACL 2024.</p></li> 
<li><p>&ldquo;<a href="https://www.researchgate.net/publication/379527692_Accelerated_Neural_Enhancement_for_Video_Analytics_With_Video_Quality_Adaptation#fullTextFileContent">Accelerated Neural Enhancement for Video Analytics with Video Quality Adaptation</a>&rdquo;, ACM/IEEE TON 2024.</p></li> 
<li><p>&ldquo;<a href="https://arxiv.org/pdf/2401.05459.pdf">Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security</a>&rdquo;, arXiv, Jan 2024. [<a href="https://mp.weixin.qq.com/s/JYB4BzsXhWF8pEUUkvn_GQ">机器之心</a>] [<a href="https://developer.huawei.com/consumer/cn/doc/guidebook/terminals-ai-0000001929853698">AI终端白皮书</a>] <a href="https://github.com/MobileLLM/Personal_LLM_Agents_Survey?tab=readme-ov-file"><img src="img/github.png" alt="github" height="22px" style="vertical-align:middle" /></a></p></li>
</ul>
<style>
.scrollable {
  height: 300px; /* 或你希望的任何高度 */
  overflow-y: scroll; /* 在垂直方向上启用滚动 */
  padding: 0px;
  border: none; /* 可选，增加边框以便更清晰地看到滚动区域的边界 */
}
</style>
<h2>News </h2>
<div class="scrollable">
<ul>
<li><p>02/2025. PEACE was accepted by IEEE TMC. Thanks to all collaborators!</p></li>
<li><p>01/2025. VaLoRA was accepted by EuroSys'25 (Fall round). Congratulations to Mi for his first top-conference paper and many thanks to our all collaborators!</p></li>
<li><p>11/2024. My proposal on “Research on Efficient Inference of Vision-Large-Model” is approved and funded by China Postdoctoral Science Foundation. Welcome to contact me if you are interested.</p></li>
<li><p>08/2024. My proposal on “Key Technologies for Large-Model-powered Edge Video Analysis” is approved and funded by NSFC. Welcome to contact me if you are interested! We are recruiting <a style="color:rgb(116, 52, 133)" href="https://air.tsinghua.edu.cn/info/1030/1564.htm">research interns</a> of both undergraduates and graduates.</p></li>
<li><p>07/2024. RegenHance was accepted by NSDI'25 (Spring round). Many thanks to Prof. Yunxin Liu's insightful comments!</p></li>
<li><p>05/2024. SwapMoE was accepted by ACL'24. Congratulations to <a href="https://rui-kong.github.io/">Rui</a>!</p></li>
<li><p>02/2024. AccDecoder journal version was accepted by ACM/IEEE TON. Congratulations to Mi for his first top-journal paper!</p>
<p style="text-indent: 2em;">
DUET journal version was accepted by IEEE TMC. Congratulations to <a href="https://theeagleofthedesert.github.io/">Lihao</a> for his first top-journal paper!</p></li>
<li><p>01/2024. Our <a href="https://arxiv.org/pdf/2401.05459.pdf">PERSONAL LLM AGENTS - Survey</a> has been published and reported by one of the most popular WeChat Official Accounts <a href="https://mp.weixin.qq.com/s/JYB4BzsXhWF8pEUUkvn_GQ">机器之心</a>!! Check out it and <a href="https://github.com/MobileLLM/Personal_LLM_Agents_Survey?tab=readme-ov-file">Repo</a> for more details. </p></li>
<li><p>12/2023. BiSwift was accepted to IEEE INFOCOM'24. Congratulations to <a href="https://sunnie-star.github.io/">Lin</a> for her first top-conference paper!</p></li>
<li><p>11/2023. DARPA journal version was accepted by IEEE TMC. Thanks to all collaborators!</p></li>
<li><p>07/2023. I was elected to the Postdoctoral Talent Introduction Program from the Ministry of Education, China (国家博士后海外引才专项) and the Shuimu Tsinghua Scholar Program from Tsinghua University (水木学者). Many thanks to my Postdoc holder Prof. Yunxin Liu.</p>
</li>
<li><p>04/2023. VSiM journal version was accepted to TON. Many thanks to our collaborators Yali, Yuhan, Sripriya, Kai, and Prof. Xiaoming Fu!</p>
</li>
<!-- <li><p>12/2022. One paper was accepted to IEEE INFOCOM'23. Conguratulations to <a href="https://sites.google.com/view/tyuan">Tingting Yuan</a> and Liang Mi!</p></li>
<li><p>09/2022. My doctoral dissertation was awarded the highest grade "summa cum laude" (Top 1% of PhD graduates@UGöttingen, Germany). Sincerely appreciate my supervisor Prof. Xiaoming Fu.</p></li> -->
</ul>
</div>
<div id="footer">
<div id="footer-text">
Page generated 2023-04-04, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
